{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6jaRArVua76"
      },
      "source": [
        "## Is it a red apple or green apple or a pear?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyIOHIJGua78"
      },
      "outputs": [],
      "source": [
        "#NB: Kaggle requires phone verification to use the internet or a GPU. If you haven't done that yet, the cell below will fail\n",
        "#    This code is only here to check that your internet is enabled. It doesn't do anything else.\n",
        "#    Here's a help thread on getting your phone number verified: https://www.kaggle.com/product-feedback/135367\n",
        "\n",
        "import socket,warnings\n",
        "try:\n",
        "    socket.setdefaulttimeout(1)\n",
        "    socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect(('1.1.1.1', 53))\n",
        "except socket.error as ex: raise Exception(\"STOP: No internet. Click '>|' in top right and set 'Internet' switch to on\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBkBgdY4ua79"
      },
      "outputs": [],
      "source": [
        "# It's a good idea to ensure you're running the latest version of any libraries you need.\n",
        "# `!pip install -Uqq <libraries>` upgrades to the latest version of <libraries>\n",
        "# NB: You can safely ignore any warnings or errors pip spits out about running as root or incompatibilities\n",
        "import os\n",
        "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
        "\n",
        "if iskaggle:\n",
        "    !pip install -Uqq fastai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8q51e2kua7-"
      },
      "source": [
        "In 2015 the idea of creating a computer system that could recognise birds was considered so outrageously challenging that it was the basis of [this XKCD joke](https://xkcd.com/1425/):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ovJl3Rtua7-"
      },
      "source": [
        "![image.png](attachment:a0483178-c30e-4fdd-b2c2-349e130ab260.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czCPhwjvua7-"
      },
      "source": [
        "But today, we can do exactly that, in just a few minutes, using entirely free resources!\n",
        "\n",
        "The basic steps we'll take are:\n",
        "\n",
        "1. Use DuckDuckGo to search for images of \"green apple photos\"\n",
        "1. Use DuckDuckGo to search for images of \"pear photos\"\n",
        "1. Fine-tune a pretrained neural network to recognise these two groups\n",
        "1. Try running this model on a picture of a pear and see if it works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9KDkHxxua8A"
      },
      "source": [
        "## Step 1: Download images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfQaHMRuua8A"
      },
      "outputs": [],
      "source": [
        "# Skip this cell if you already have duckduckgo_search installed\n",
        "!pip install -Uqq ddgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr2t_4iLua8B"
      },
      "outputs": [],
      "source": [
        "from ddgs import DDGS\n",
        "from fastcore.all import *\n",
        "\n",
        "\n",
        "def search_images(keywords, max_images=200): return L(DDGS().images(keywords, max_results=max_images)).itemgot('image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDcLRPxkua8C"
      },
      "source": [
        "Let's start by searching for a green apple photo and seeing what kind of result we get. We'll start by getting URLs from a search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5wjnRviua8D"
      },
      "outputs": [],
      "source": [
        "urls = search_images('french_bulldog', max_images=1)\n",
        "urls[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qna2ICtLua8D"
      },
      "source": [
        "...and then download a URL and take a look at it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Twe2GjEXua8D"
      },
      "outputs": [],
      "source": [
        "from fastdownload import download_url\n",
        "dest = 'french_bulldog.jpg'\n",
        "download_url(urls[0], dest, show_progress=False)\n",
        "\n",
        "from fastai.vision.all import *\n",
        "im = Image.open(dest)\n",
        "im.to_thumb(256,256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YavAj3Rjua8E"
      },
      "source": [
        "Now let's do the same with \"Pear photos\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O0cbehtua8E"
      },
      "outputs": [],
      "source": [
        "download_url(search_images('pug photos', max_images=1)[0], 'pug.jpg', show_progress=False)\n",
        "Image.open('pug.jpg').to_thumb(256,256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9eie9_eua8E"
      },
      "source": [
        "Our searches seem to be giving reasonable results, so let's grab 200 examples of each of \"green apple\", \"red apple\" and \"pear\" photos, and save each group of photos to a different folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rys5GAFSua8E"
      },
      "outputs": [],
      "source": [
        "searches = 'french_bulldog','pug_dog'\n",
        "path = Path('french_bulldog_or_pug_dog')\n",
        "from time import sleep\n",
        "\n",
        "for o in searches:\n",
        "    dest = (path/o)\n",
        "    dest.mkdir(exist_ok=True, parents=True)\n",
        "    download_images(dest, urls=search_images(f'{o} photo'))\n",
        "    sleep(10)  # Pause between searches to avoid over-loading server\n",
        "    download_images(dest, urls=search_images(f'{o} old photo'))\n",
        "    sleep(10)\n",
        "    download_images(dest, urls=search_images(f'{o} baby photo'))\n",
        "    sleep(10)\n",
        "    resize_images(path/o, max_size=400, dest=path/o)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHAyVO3Xua8F"
      },
      "source": [
        "## Step 2: Train our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSLcqBGFua8F"
      },
      "source": [
        "Some photos might not download correctly which could cause our model training to fail, so we'll remove them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fToH_YV5ua8F"
      },
      "outputs": [],
      "source": [
        "failed = verify_images(get_image_files(path))\n",
        "failed.map(Path.unlink)\n",
        "len(failed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ2_T53Bua8G"
      },
      "source": [
        "To train a model, we'll need `DataLoaders`, which is an object that contains a *training set* (the images used to create a model) and a *validation set* (the images used to check the accuracy of a model -- not used during training). In `fastai` we can create that easily using a `DataBlock`, and view sample images from it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mcfrpXsua8G"
      },
      "outputs": [],
      "source": [
        "dogs = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y=parent_label,\n",
        "    # item_tfms=[Resize(192, method='pad',pad_mode='zeros')],\n",
        "    item_tfms=Resize(128)\n",
        ")\n",
        "dls = dogs.dataloaders(path)\n",
        "\n",
        "\n",
        "\n",
        "dls.valid.show_batch(max_n=8, nrows=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Augmentation\n",
        "\n",
        "dogs = dogs.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2))\n",
        "dls = dogs.dataloaders(path)\n",
        "dls.train.show_batch(max_n=8, nrows=2, unique=True)"
      ],
      "metadata": {
        "id": "GyIgVlB3KBBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dogs = dogs.new(\n",
        "#     item_tfms=RandomResizedCrop(224, min_scale=0.5),\n",
        "#     batch_tfms=aug_transforms())\n",
        "# dls = dogs.dataloaders(path)\n",
        "\n",
        "# dls.show_batch(max_n=10)"
      ],
      "metadata": {
        "id": "CyQmAhQgKTzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VEAcOWRua8H"
      },
      "source": [
        "Here is what each of the `DataBlock` parameters means:\n",
        "\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "\n",
        "The inputs to our model are images, and the outputs are categories (in this case, \"bird\" or \"forest\").\n",
        "\n",
        "    get_items=get_image_files,\n",
        "\n",
        "To find all the inputs to our model, run the `get_image_files` function (which returns a list of all image files in a path).\n",
        "\n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "\n",
        "Split the data into training and validation sets randomly, using 20% of the data for the validation set.\n",
        "\n",
        "    get_y=parent_label,\n",
        "\n",
        "The labels (`y` values) is the name of the `parent` of each file (i.e. the name of the folder they're in, which will be *bird* or *forest*).\n",
        "\n",
        "    item_tfms=[Resize(192, method='squish')]\n",
        "\n",
        "Before training, resize each image to 192x192 pixels by \"squishing\" it (as opposed to cropping it)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8372JaXua8H"
      },
      "source": [
        "Now we're ready to train our model. The fastest widely used computer vision model is `resnet18`. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds...)\n",
        "\n",
        "`fastai` comes with a helpful `fine_tune()` method which automatically uses best practices for fine tuning a pre-trained model, so we'll use that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sXfoqsEua8H"
      },
      "outputs": [],
      "source": [
        "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
        "learn.fine_tune(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra_FsShsua8I"
      },
      "source": [
        "Generally when I run this I see 100% accuracy on the validation set (although it might vary a bit from run to run).\n",
        "\n",
        "\"Fine-tuning\" a model means that we're starting with a model someone else has trained using some other dataset (called the *pretrained model*), and adjusting the weights a little bit so that the model learns to recognise your particular dataset. In this case, the pretrained model was trained to recognise photos in *imagenet*, and widely-used computer vision dataset with images covering 1000 categories) For details on fine-tuning and why it's important, check out the [free fast.ai course](https://course.fast.ai/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E153oRL0ua8I"
      },
      "source": [
        "## Step 3: Use our model (and build your own!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LjG7vRuua8J"
      },
      "source": [
        "Let's see what our model thinks about that pear we downloaded at the start:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDtM3E7Eua8J"
      },
      "outputs": [],
      "source": [
        "is_pear,_,probs = learn.predict(PILImage.create('pug.jpg'))\n",
        "print(f\"This is a: {is_pear}.\")\n",
        "print(f\"Probability it's a pear: {probs[0]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()"
      ],
      "metadata": {
        "id": "EbzwoiYWenfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check th issues\n",
        "interp.plot_top_losses(11, nrows=6)"
      ],
      "metadata": {
        "id": "muhjKoV6iEJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide_output\n",
        "from fastai.vision.widgets import ImageClassifierCleaner\n",
        "\n",
        "cleaner = ImageClassifierCleaner(learn)\n",
        "cleaner"
      ],
      "metadata": {
        "id": "df4yCpPzj-Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in cleaner.delete(): cleaner.fns[idx].unlink()\n",
        "for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)"
      ],
      "metadata": {
        "id": "oxFkSIcDl-_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dogs = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y=parent_label,\n",
        "    # item_tfms=[Resize(192, method='pad',pad_mode='zeros')],\n",
        "    item_tfms=Resize(128)\n",
        ")\n",
        "\n",
        "dogs = dogs.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2))\n",
        "dls = dogs.dataloaders(path)\n",
        "dls.show_batch(max_n=8, nrows=2, unique=True)"
      ],
      "metadata": {
        "id": "SV7xMBZime98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
        "learn.fine_tune(4)"
      ],
      "metadata": {
        "id": "5IZlKwpinHJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.export()"
      ],
      "metadata": {
        "id": "fRVDrOChp28O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4hrkK3sua8J"
      },
      "source": [
        "Good job, resnet18. :)\n",
        "\n",
        "So, as you see, in the space of a few years, creating computer vision classification models has gone from \"so hard it's a joke\" to \"trivially easy and free\"!\n",
        "\n",
        "It's not just in computer vision. Thanks to deep learning, computers can now do many things which seemed impossible just a few years ago, including [creating amazing artworks](https://openai.com/dall-e-2/), and [explaining jokes](https://www.datanami.com/2022/04/22/googles-massive-new-language-model-can-explain-jokes/). It's moving so fast that even experts in the field have trouble predicting how it's going to impact society in the coming years.\n",
        "\n",
        "One thing is clear -- it's important that we all do our best to understand this technology, because otherwise we'll get left behind!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx6IhaXjua8J"
      },
      "source": [
        "Now it's your turn. Click \"Copy & Edit\" and try creating your own image classifier using your own image searches!\n",
        "\n",
        "If you enjoyed this, please consider clicking the \"upvote\" button in the top-right -- it's very encouraging to us notebook authors to know when people appreciate our work."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}